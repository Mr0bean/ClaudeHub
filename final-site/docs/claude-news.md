---
title: "Claude 新闻时间线 | ClaudeLog"
---

# Claude 新闻时间线 | ClaudeLog

获取 Anthropic 关于 Claude 的最新公告、产品更新和新闻动态。

* * *

* * *

## **2025年9月**[​](#september-2025 "Direct link to september-2025")

### [为工作团队带来记忆功能](https://www.anthropic.com/news/memory)[​](#bringing-memory-to-teams-at-work "Direct link to bringing-memory-to-teams-at-work")

Claude 引入了 `记忆` 功能，能够记住你和你团队的项目、偏好和工作模式，消除了在持续对话中重新解释上下文的需要。记忆功能为 `每个项目创建单独的记忆`，确保机密讨论保持隔离，同时在复杂项目中保持连续性。该功能包括用于敏感对话的 `隐身聊天`，不会保存到记忆或历史记录中，以及 `细粒度用户控制`，允许你查看和编辑 Claude 记住的确切内容。

9月11日, 2025年 | 类别：产品

* * *

### [Claude 现在可以创建和编辑文件](https://www.anthropic.com/news/create-files)[​](#claude-can-now-create-and-edit-files "Direct link to claude-can-now-create-and-edit-files")

Claude 现在可以直接在 `Claude.ai` 和 `桌面应用` 中创建和编辑 `Excel 电子表格`、`文档`、`PowerPoint 幻灯片` 和 `PDF`, 通过从指令和数据生成即用文件，改变用户的工作方式. 此功能作为预览版提供给 `Max`、`Team` 和 `Enterprise` 用户，`Pro` 用户将在 `未来几周内` 获得访问权限.

9月9日, 2025年 | 类别：产品

* * *

### [Anthropic 支持 SB 53 法案](https://www.anthropic.com/news/anthropic-is-endorsing-sb-53)[​](#anthropic-is-endorsing-sb-53 "Direct link to anthropic-is-endorsing-sb-53")

Anthropic 支持加州的 `SB 53` 法案，这是一项管理强大 AI 系统的法案 要求公司开发 `安全框架`、发布 `透明度报告`，并向州政府报告 `关键事件`. 公司支持这种 `信任但验证` 的方法，因为它将 `前沿 AI 公司` 已经遵循的做法正式化 同时为安全披露创造公平的竞争环境.

9月8日, 2025年 | 类别：公告

* * *

### [更新对不支持地区的销售限制](https://www.anthropic.com/news/updating-restrictions-of-sales-to-unsupported-regions)[​](#updating-restrictions-of-sales-to-unsupported-regions "Direct link to updating-restrictions-of-sales-to-unsupported-regions")

Anthropic 正在加强地区限制，以防止受 `中国` 等敌对国家控制的公司 访问其服务，即使是通过其他国家的子公司. 更新后的政策禁止由不支持地区公司 `持股超过50%` 的实体, 解决专制政府可能强制数据共享和情报合作的 `国家安全风险`.

9月4日, 2025年 | 类别：公告

* * *

### [Anthropic 完成130亿美元F轮融资，投后估值1830亿美元](https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation)[​](#anthropic-raises-13b-series-f-at-183b-post-money-valuation "Direct link to anthropic-raises-13b-series-f-at-183b-post-money-valuation")

Anthropic 完成了由 `ICONIQ` 领投的 `130亿美元` `F轮` 融资, 公司投后估值达 `1830亿美元`，主要投资者包括 `Fidelity`、`Lightspeed` 和 `BlackRock`. 这笔融资反映了 Anthropic 从 `2025年初` `10亿美元` 年化收入的快速增长 到 `8月` 超过 `50亿美元`，使其成为历史上增长最快的科技公司之一.

9月2日, 2025年 | 类别：公告

* * *

* * *

## **2025年8月**[​](#august-2025 "Direct link to august-2025")

### [消费者条款和隐私政策更新](https://www.anthropic.com/news/updates-to-our-consumer-terms)[​](#updates-to-consumer-terms-and-privacy-policy "Direct link to updates-to-consumer-terms-and-privacy-policy")

Anthropic 更新了消费者条款和隐私政策，允许使用来自 `Free`、`Pro` 和 `Max` 账户的数据训练新模型 当用户 `选择加入` 时，同意者的数据保留期延长至 `5年`. 现有用户需在 `2025年9月28日` 前做出选择，新用户在注册时选择.

8月28日, 2025年 | 类别：产品

* * *

### [推出 Anthropic 国家安全和公共部门咨询委员会](https://www.anthropic.com/news/introducing-the-anthropic-national-security-and-public-sector-advisory-council)[​](#introducing-the-anthropic-national-security-and-public-sector-advisory-council "Direct link to introducing-the-anthropic-national-security-and-public-sector-advisory-council")

Anthropic 成立了 `国家安全和公共部门咨询委员会`, 成员包括 `两党` 前政府领导人，包括参议员 `Roy Blunt` 和 `Jon Tester`, 前 `国防官员` 和 `情报界资深人士`. 委员会将帮助确定 `国家安全` 的高影响力 AI 应用, 制定行业标准，并加强 `公私合作伙伴关系`.

8月27日, 2025年 | 类别：公告

* * *

### [检测和打击 AI 滥用：2025年8月](https://www.anthropic.com/news/detecting-countering-misuse-aug-2025)[​](#detecting-and-countering-misuse-of-ai-august-2025 "Direct link to detecting-and-countering-misuse-of-ai-august-2025")

Anthropic 的威胁情报报告揭示了复杂的 AI 滥用 包括使用 `Claude Code` 的 `大规模勒索行动`, `朝鲜` 就业欺诈计划，以及 `AI生成的勒索软件` 销售. 报告显示，网络犯罪分子正在将 `代理AI` 武器化以执行攻击，而不仅仅是提供建议, 降低了 `技术技能最少` 的行为者进行复杂网络犯罪的门槛.

8月27日, 2025年 | 类别：公告

* * *

### [Claude Code 和商业计划的新管理控制](https://www.anthropic.com/news/claude-code-on-team-and-enterprise)[​](#claude-code-and-new-admin-controls-for-business-plans "Direct link to claude-code-and-new-admin-controls-for-business-plans")

`Claude Code` 现在通过 `高级席位` 向 `Team` 和 `Enterprise` 客户提供 包括增强的使用和编码能力, 允许在构思和实施之间无缝过渡. 新的管理控制包括 `自助席位管理`、`细粒度支出控制`, `使用分析` 和用于实时程序化访问使用数据的 `合规API`.

8月20日, 2025年 | 类别：产品

* * *

### [Anthropic 任命 Hidetoshi Tojo 为日本负责人并宣布招聘计划](https://www.anthropic.com/news/head-of-japan-hiring-plans)[​](#anthropic-appoints-hidetoshi-tojo-as-head-of-japan-and-announces-hiring-plans "Direct link to anthropic-appoints-hidetoshi-tojo-as-head-of-japan-and-announces-hiring-plans")

Anthropic 任命 `Hidetoshi Tojo` 为日本负责人, 他在扩展科技公司方面拥有丰富经验，包括 `Snowflake`、`Google Cloud` 和 `Microsoft` 在日本的运营. 此任命支持 Anthropic 的扩张计划，包括在 `东京` 开设他们的 `首个亚洲办事处` 并雇用本地人才为日本客户服务.

8月6日, 2025年 | 类别：公告

* * *

### [使用 Claude Code 自动化安全审查](https://www.anthropic.com/news/automate-security-reviews-with-claude-code)[​](#automate-security-reviews-with-claude-code "Direct link to automate-security-reviews-with-claude-code")

`Claude Code` 通过新的 `/security-review` 命令引入了自动化安全审查 和 `GitHub Actions` 集成，可识别 `SQL注入`、`XSS` 等漏洞, 以及在代码投入生产前的 `身份验证缺陷`. 这些功能允许从终端进行 `临时安全分析` 以及带有内联评论和修复建议的 `自动拉取请求审查`.

8月6日, 2025年 | 类别：公告

* * *

* * *

## **2025年7月**[​](#july-2025 "Direct link to july-2025")

### [Anthropic 签署欧盟行为准则](https://www.anthropic.com/news/eu-code-practice)[​](#anthropic-to-sign-the-eu-code-of-practice "Direct link to anthropic-to-sign-the-eu-code-of-practice")

Anthropic 宣布其签署 `欧盟通用人工智能行为准则` 的意向，将其视为推进前沿 AI 开发的 `透明度`、`安全性` 和 `问责制` 原则。该准则建立了基于 Anthropic 的 `负责任扩展政策` 的强制性 `安全和保障框架`，同时保持适应不断发展技术的灵活性。

7月21日, 2025年 | 类别：政策

* * *

### [Paul Smith 将加入 Anthropic 担任首席商务官](https://www.anthropic.com/news/paul-smith-to-join-anthropic)[​](#paul-smith-to-join-anthropic-as-chief-commercial-officer "Direct link to paul-smith-to-join-anthropic-as-chief-commercial-officer")

`Paul Smith` 将在 `2025年` 晚些时候加入 Anthropic 担任其 `首任首席商务官`，拥有超过 `30年` 在 `Microsoft`、`Salesforce` 和 `ServiceNow` 构建全球市场推广组织的经验。这一任命正值公司异常增长期间，拥有 `数十万` 活跃 API 客户，`Claude Code` 收入在 `两个月` 内增长超过 `5倍`。

7月15日, 2025年 | 类别：公告

* * *

### [Anthropic 与国防部推进国防运营中的负责任 AI](https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations)[​](#anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations "Direct link to anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations")

Anthropic 从 `美国国防部` 获得了一项价值 `2亿美元`、为期 `两年` 的协议，为 `国家安全应用` 开发前沿 AI 能力原型。该合作将专注于开发基于 `国防部` 数据进行微调的工作原型，在 `对抗性 AI 缓解` 方面进行合作，并加速在国防运营中负责任地采用 AI。

7月14日, 2025年 | 类别：公告

* * *

* * *

## **2025年6月**[​](#june-2025 "Direct link to june-2025")

### [国家安全专家 Richard Fontaine 被任命为 Anthropic 长期利益信托成员](https://www.anthropic.com/news/national-security-expert-richard-fontaine-appointed-to-anthropic-s-long-term-benefit-trust)[​](#national-security-expert-richard-fontaine-appointed-to-anthropics-long-term-benefit-trust "Direct link to national-security-expert-richard-fontaine-appointed-to-anthropics-long-term-benefit-trust")

`新美国安全中心` CEO `Richard Fontaine` 被任命为 Anthropic 的 `长期利益信托` 成员，他拥有丰富的 `国家安全经验`，包括在 `国家安全委员会`、`国务院` 以及 `国防政策委员会` 的任职经历。他的任命解决了 `AI 能力` 与 `地缘政治风险` 之间日益增长的交集，加强了信托指导 Anthropic 做出复杂决策的能力。

6月7日, 2025年 | 类别：公告

* * *

* * *

## **2025年5月**[​](#may-2025 "Direct link to may-2025")

### [Reed Hastings 被任命为 Anthropic 董事会成员](https://www.anthropic.com/news/reed-hastings)[​](#reed-hastings-appointed-to-anthropics-board-of-directors "Direct link to reed-hastings-appointed-to-anthropics-board-of-directors")

`Netflix` 联合创始人兼前 CEO `Reed Hastings` 被 `长期利益信托` 任命为 Anthropic 的 `董事会成员`。`Hastings` 带来了 `25年以上` 的扩展经验，最近捐赠了 `5000万美元` 在 `鲍登学院` 建立 `AI 与人类研究倡议`。

5月28日, 2025年 | 类别：公告

* * *

### [Anthropic API 上构建代理的新功能](https://www.anthropic.com/news/agent-capabilities-api)[​](#new-capabilities-for-building-agents-on-the-anthropic-api "Direct link to new-capabilities-for-building-agents-on-the-anthropic-api")

Anthropic 宣布了用于构建 AI 代理的 `四项新 API 功能`：用于 `Python` 分析的 `代码执行工具`、用于外部系统集成的 `MCP 连接器`、用于文档管理的 `文件 API`，以及延长至 `一小时` 的 `提示缓存`。这些功能使开发人员能够构建更强大的代理，可以执行代码、连接第三方服务、跨会话管理文件，并以 `成本效益` 的方式维持上下文。

5月22日, 2025年 | 类别：产品

* * *

* * *

## **2025年4月**[​](#april-2025 "Direct link to april-2025")

### [Claude 将研究带到新高度](https://www.anthropic.com/news/research)[​](#claude-takes-research-to-new-places "Direct link to claude-takes-research-to-new-places")

Anthropic 推出了 `研究功能`，使 Claude 能够进行 `多步骤网络搜索` 以及连接 `Gmail`、`日历` 和 `Google 文档` 的 `Google Workspace` 集成。研究功能允许 Claude 以 `代理方式` 运作，探索不同角度并构建带有引用的 `全面答案`，而 Google Workspace 集成提供更深入的工作上下文，无需手动上传文件。

4月15日, 2025年 | 类别：产品

* * *

### [Anthropic 任命 Guillaume Princen 为 EMEA 负责人并宣布在该地区新增 100+ 个职位](https://www.anthropic.com/news/head-of-EMEA-new-roles)[​](#anthropic-appoints-guillaume-princen-as-head-of-emea-and-announces-100-new-roles-across-the-region "Direct link to anthropic-appoints-guillaume-princen-as-head-of-emea-and-announces-100-new-roles-across-the-region")

`Guillaume Princen` 被任命为 Anthropic 的 `EMEA 负责人`，他拥有丰富的经验，包括在 `12 个办事处` 扩展 `Stripe` 的欧洲业务以及担任 `Mooncard` 的 CEO。Anthropic 计划今年在 `都柏林` 和 `伦敦` 办事处创建超过 `100 个新职位`，涵盖销售、工程、研究和运营等领域。

4月8日, 2025年 | 类别：公告

* * *

### [介绍 Anthropic 首届开发者大会：Code with Claude](https://www.anthropic.com/news/Introducing-code-with-claude)[​](#introducing-anthropics-first-developer-conference-code-with-claude "Direct link to introducing-anthropics-first-developer-conference-code-with-claude")

Anthropic 宣布了 `Code with Claude`，这是其 `首届开发者大会`，将于 `2025年5月22日` 在 `旧金山` 的 `The Midway` 举行。这个实践性活动将专注于使用 `Anthropic API`、`CLI 工具` 和 `模型上下文协议 (MCP)` 的真实世界实现，包括互动研讨会、产品路线图讨论和网络交流机会。

4月3日, 2025年 | 类别：活动

* * *

* * *

## **2025年3月**[​](#march-2025 "Direct link to march-2025")

### [我们前沿红队的进展](https://www.anthropic.com/news/strategic-warning-for-ai-risk-progress-and-insights-from-our-frontier-red-team)[​](#progress-from-our-frontier-red-team "Direct link to progress-from-our-frontier-red-team")

Anthropic 的 `前沿红队` 报告了 AI 在 `网络安全` 和 `生物学` 领域能力的显著进展，Claude 在 `一年` 内在网络安全 CTF 挑战中从 `高中水平` 提升到 `本科水平`。虽然模型在双用途能力方面显示出 `早期预警信号` 并在一些生物学任务中超越了 `专家基准`，但它们仍然没有达到显著提高 `国家安全风险` 的阈值。

3月19日, 2025年 | 类别：政策

* * *

* * *

## **2025年2月**[​](#february-2025 "Direct link to february-2025")

### [Anthropic 与美国国家实验室合作举办首届 1000 名科学家 AI 大会](https://www.anthropic.com/news/anthropic-partners-with-u-s-national-labs-for-first-1-000-scientist-ai-jam)[​](#anthropic-partners-with-us-national-labs-for-first-1000-scientist-ai-jam "Direct link to anthropic-partners-with-us-national-labs-for-first-1000-scientist-ai-jam")

Anthropic 与 `美国能源部` 合作举办首届 `1000 名科学家 AI 大会`，汇集来自多个 `国家实验室` 的科学家，评估 `Claude 3.7 Sonnet` 在科学研究和 `国家安全应用` 方面的表现。该活动将测试 Claude 在现实世界研究问题上的能力，包括 `假设生成`、`实验规划` 和 `结果分析`。

2月28日, 2025年 | 类别：公告

* * *

### [介绍 Anthropic 的透明度中心](https://www.anthropic.com/news/introducing-anthropic-transparency-hub)[​](#introducing-anthropics-transparency-hub "Direct link to introducing-anthropics-transparency-hub")

Anthropic 推出了其 `透明度中心`，提供关于 `安全协议`、`风险缓解策略`、`平台滥用检测` 和 `治理政策` 的详细信息。该中心包括关于关键指标如 `被禁账户`、`申诉` 和 `政府请求` 的首份定期报告，旨在作为一个统一框架来满足多样化的透明度要求。

2月27日, 2025年 | 类别：社会影响

* * *

### [Claude 和 Alexa+](https://www.anthropic.com/news/claude-and-alexa-plus)[​](#claude-and-alexa "Direct link to claude-and-alexa")

Claude 模型现在通过 Anthropic 和亚马逊团队的合作为 `亚马逊的 Alexa+` 提供支持，Anthropic 的首席产品官 `Mike Krieger` 领导集成工作。Alexa+ 受益于 Claude 的 `先进能力` 和 `安全功能`，包括 `防越狱能力`，并通过 `Amazon Bedrock` 访问 Claude。

2月26日, 2025年 | 类别：公告

* * *

### [Dario Amodei 对巴黎 AI 行动峰会的声明](https://www.anthropic.com/news/paris-ai-summit)[​](#statement-from-dario-amodei-on-the-paris-ai-action-summit "Direct link to statement-from-dario-amodei-on-the-paris-ai-action-summit")

`Dario Amodei` 在 `巴黎 AI 行动峰会` 后发表声明，强调需要更多关注的三个关键领域：确保 `民主社会` 在 AI 发展中起主导作用，应对日益增长的安全风险包括 `CBRN 威胁` 和 `自主 AI 危险`，以及为 AI 进步带来的大规模 `经济颠覆` 做准备。他警告说，到 `2026-2027 年`，AI 能力可能会像 `数据中心中的天才之国`，并呼吁加快行动以匹配 AI 进步的步伐。

2月11日, 2025年 | 类别：公告

* * *

### [Lyft 将为超过 4000 万乘客和 100 万司机提供 Claude 服务](https://www.anthropic.com/news/lyft-announcement)[​](#lyft-to-bring-claude-to-more-than-40-million-riders-and-over-1-million-drivers "Direct link to lyft-to-bring-claude-to-more-than-40-million-riders-and-over-1-million-drivers")

`Lyft` 正与 Anthropic 合作，在其为超过 `4000 万乘客` 和 `100 万司机` 服务的平台上集成 Claude，重点关注 AI 驱动的解决方案、新模型的早期测试和工程改进。合作已经显示出 `显著影响`，Lyft 的 Claude 驱动客户服务助手将解决时间缩短了 `87%`，同时处理 `每日数千个查询`。

2月6日, 2025年 | 类别：公告

* * *

* * *

## **2025年1月**[​](#january-2025 "Direct link to january-2025")

### [在 Anthropic API 上引入引用功能](https://www.anthropic.com/news/introducing-citations-api)[​](#introducing-citations-on-the-anthropic-api "Direct link to introducing-citations-on-the-anthropic-api")

Anthropic 推出了 `引用功能`，这是一个新的 API 功能，允许 Claude 通过提供用于生成答案的 `确切句子` 和 `段落` 的详细引用，将其响应建立在源文档的基础上。该功能在 `Anthropic API` 和 `Google Cloud 的 Vertex AI` 上正式可用，内部评估显示与自定义实现相比，`召回准确性` 提高了多达 `15%`。

1月23日, 2025年 | 类别：产品

* * *

### [Anthropic 获得负责任 AI 的 ISO 42001 认证](https://www.anthropic.com/news/anthropic-achieves-iso-42001-certification-for-responsible-ai)[​](#anthropic-achieves-iso-42001-certification-for-responsible-ai "Direct link to anthropic-achieves-iso-42001-certification-for-responsible-ai")

Anthropic 获得了 `ISO 42001` 认证，这是 AI 治理和管理系统的`首个国际标准`，使其成为`首批获得此认证的前沿 AI 实验室之一`。该认证验证了 Anthropic 通过政策、测试、透明度措施和既定监督责任来识别、评估和缓解 AI 风险的综合框架。

1月13日, 2025年 | 类别：公告

* * *

* * *

## **2024年12月**[​](#december-2024 "Direct link to december-2024")

### [2024年选举与AI：观察和学习](https://www.anthropic.com/news/elections-ai-2024)[​](#elections-and-ai-in-2024-observations-and-learnings "Direct link to elections-and-ai-in-2024-observations-and-learnings")

Anthropic 发布了对 `2024 年选举周期`的观察结果，指出与选举相关的活动占 Claude 总使用量的不到 `0.5%`，在选举高峰周上升至略超过 `1%`。该公司实施了全面的安全措施，包括政策执行、严格测试和引导用户访问权威来源，同时使用他们新的 `Clio 工具`来分析使用模式并确保选举期间负责任的 AI 部署。

12月12日, 2024年 | 类别：社会影响

* * *

### [AWS Trainium2 上的 Claude 3.5 Haiku 和 Amazon Bedrock 中的模型蒸馏](https://www.anthropic.com/news/trainium2-and-distillation)[​](#claude-35-haiku-on-aws-trainium2-and-model-distillation-in-amazon-bedrock "Direct link to claude-35-haiku-on-aws-trainium2-and-model-distillation-in-amazon-bedrock")

Anthropic 宣布了 `Claude 3.5 Haiku` 针对 `AWS Trainium2` 芯片的优化，提供高达 `60%` 的推理速度提升，并在 `Amazon Bedrock` 中引入了模型蒸馏技术，使 `Claude 3 Haiku` 能够在特定任务上达到类似 `Claude 3.5 Sonnet` 的准确性。该公司还将 `Claude 3.5 Haiku` 的价格降至每百万输入令牌 `0.80 美元`，每百万输出令牌 `4 美元`，适用于所有平台。

12月3日, 2024年 | 类别：产品

* * *

* * *

## **2024年11月**[​](#november-2024 "Direct link to november-2024")

### [定制 Claude 的响应以匹配您的个人风格](https://www.anthropic.com/news/styles)[​](#tailor-claudes-responses-to-your-personal-style "Direct link to tailor-claudes-responses-to-your-personal-style")

Anthropic 为 `Claude.ai` 引入了 `自定义风格` 功能，允许用户定制 Claude 的响应以匹配他们的沟通偏好、语调和结构。用户可以从 `预设选项`（`正式`、`简洁`、`解释性`）中选择，或通过上传示例内容生成 `自定义风格`，使 Claude 能够适应个人的工作流程和写作偏好。

11月26日, 2024年 | 类别：产品

* * *

### [介绍模型上下文协议](https://www.anthropic.com/news/model-context-protocol)[​](#introducing-the-model-context-protocol "Direct link to introducing-the-model-context-protocol")

Anthropic 开源了 `模型上下文协议 (MCP)`，这是一个连接 AI 助手到数据源的新标准，包括内容仓库、商业工具和开发环境。MCP 提供了一个 `通用协议` 来替代分散的集成，在 `Claude Desktop` 应用中提供 `本地服务器支持`，并为流行的企业系统如 `Google Drive`、`Slack`、`GitHub` 和 `Postgres` 提供预构建服务器。

11月25日, 2024年 | 类别：公告

* * *

### [与 AWS 共同推动下一代 AI 开发](https://www.anthropic.com/news/anthropic-amazon-trainium)[​](#powering-the-next-generation-of-ai-development-with-aws "Direct link to powering-the-next-generation-of-ai-development-with-aws")

Anthropic 宣布与 `AWS` 扩大 `40 亿美元` 的合作伙伴关系，使亚马逊的总投资达到 `80 亿美元`，同时确立 AWS 为其 `主要云和训练合作伙伴`。这次合作包括在 `AWS Trainium` 加速器上的深度技术工作，Anthropic 将为硬件优化和 `AWS Neuron` 软件栈贡献力量，以训练他们最先进的基础模型。

11月22日, 2024年 | 类别：公告

* * *

### [在开发者控制台中改进您的提示](https://www.anthropic.com/news/prompt-improver)[​](#improve-your-prompts-in-the-developer-console "Direct link to improve-your-prompts-in-the-developer-console")

Anthropic 在开发者控制台中推出了 `提示改进功能`，该功能使用先进的工程技术如 `思维链推理` 和 `示例标准化` 自动完善现有提示。该工具还包括 `结构化示例管理` 和 `评估能力`，测试显示分类任务的准确性提高了 `30%`，摘要任务的字数遵循度达到 `100%`。

11月14日, 2024年 | 类别：产品

* * *

* * *

## **2024年10月**[​](#october-2024 "Direct link to october-2024")

### [针对性监管的理由](https://www.anthropic.com/news/the-case-for-targeted-regulation)[​](#the-case-for-targeted-regulation "Direct link to the-case-for-targeted-regulation")

Anthropic 发布了他们在 AI 监管方面的立场，倡导基于 `RSP（负责任扩展政策）`的针对性监管，重点关注 `透明度`，激励更好的 `安全实践`，并保持 `简洁性`。该公司认为政府应在 `18 个月` 内紧急行动，实施比例适当的监管来应对 `灾难性风险`，同时支持创新，强调需要 `精准而非广泛` 的监管方法。

10月31日, 2024年 | 类别：政策

* * *

### [GitHub Copilot 上的 Claude 3.5 Sonnet](https://www.anthropic.com/news/github-copilot)[​](#claude-35-sonnet-on-github-copilot "Direct link to claude-35-sonnet-on-github-copilot")

`Claude 3.5 Sonnet` 在 `GitHub Copilot` 上可用，通过 `Visual Studio Code` 和 `GitHub.com` 将 Claude 的编码能力带给超过 `1 亿开发者`。升级的模型在 `SWE-bench Verified` 上超越了所有公开可用的模型，在 `HumanEval` 上达到 `93.7%`，使开发者能够编写生产就绪的代码、通过内联聊天进行调试，并创建全面的测试套件。

10月29日, 2024年 | 类别：公告

* * *

### [在 Claude.ai 中引入分析工具](https://www.anthropic.com/news/analysis-tool)[​](#introducing-the-analysis-tool-in-claudeai "Direct link to introducing-the-analysis-tool-in-claudeai")

Anthropic 在 `Claude.ai` 中推出了 `分析工具`，这是一个内置的 `JavaScript` 代码沙盒，使 Claude 能够编写和运行代码进行数据处理、分析和 `实时洞察`。该工具允许 Claude 像 `数据分析师` 一样工作，系统地处理来自 `CSV 文件` 的数据，为包括 `营销`、`销售`、`产品管理` 和 `财务` 在内的各种业务团队提供 `数学精确` 和 `可重现的答案`。

10月24日, 2024年 | 类别：产品

* * *

### [开发计算机使用模型](https://www.anthropic.com/news/developing-computer-use)[​](#developing-a-computer-use-model "Direct link to developing-a-computer-use-model")

Anthropic 宣布了 Claude 新的`计算机使用能力`，允许 AI 像人类一样通过`截图`、`移动光标`、`点击`和`打字`来控制计算机。这代表了 AI 进步的`重大突破`，使 Claude 能够`直接使用任何软件`，而不需要定制工具，尽管该功能在当前的`测试版状态`下仍然`缓慢且容易出错`。

10月22日, 2024年 | 类别：公告

* * *

### [宣布我们更新的负责任扩展政策](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy)[​](#announcing-our-updated-responsible-scaling-policy "Direct link to announcing-our-updated-responsible-scaling-policy")

Anthropic 发布了其`负责任扩展政策 (RSP)` 的重大更新，引入了更灵活的`风险评估方法`和改进的`能力阈值`以升级安全措施。更新的框架包括新的 `AI 安全级别标准`以及针对`自主 AI 研究能力`和 `CBRN 武器协助`的具体阈值，同时保持不在没有充分保障措施的情况下部署模型的核心承诺。

10月15日, 2024年 | 类别：公告

* * *

### [美国选举准备情况](https://www.anthropic.com/news/us-elections-readiness)[​](#us-elections-readiness "Direct link to us-elections-readiness")

Anthropic 概述了其针对 `2024 年美国选举`的全面`选举准备措施`，包括更新的使用政策禁止`竞选活动`和`错误信息`、`自动执行系统`，以及将用户重定向到`权威投票信息`。该公司实施了严格的控制措施以防止与选举相关的滥用，同时进行持续的`漏洞测试`和政策优化，以确保选举期间负责任的 AI 使用。

10月8日, 2024年 | 类别：社会影响

* * *

### [介绍消息批处理 API](https://www.anthropic.com/news/message-batches-api)[​](#introducing-the-message-batches-api "Direct link to introducing-the-message-batches-api")

Anthropic 推出了 `Message Batches API`，使开发者能够以比标准 API 调用低 `50%` 的成本异步处理高达 `10,000 个查询`。该服务在 `24 小时`内处理批次，并提供增强的吞吐量而不影响标准速率限制，使`大规模数据处理`对于数据集分析和文档处理等任务更具经济可行性。

10月8日, 2024年 | 类别：产品

* * *

* * *

## **2024年9月**[​](#september-2024 "Direct link to september-2024")

### [Amazon Bedrock 中的 Claude 3 Haiku 微调功能已正式可用](https://www.anthropic.com/news/fine-tune-claude-3-haiku-ga)[​](#fine-tuning-for-claude-3-haiku-in-amazon-bedrock-is-now-generally-available "Direct link to fine-tuning-for-claude-3-haiku-in-amazon-bedrock-is-now-generally-available")

`Claude 3 Haiku` 的微调功能在 `Amazon Bedrock` 中正式推出，允许开发者使用自己的数据定制`最快`且`最具成本效益`的 Claude 模型。该功能可以增强`领域专业知识`、`节省成本`和`更快的响应时间`，改进效果显示微调后的 Haiku 在专业`金融分析任务`中甚至超过了 `Claude 3.5 Sonnet` 基础模型。

9月23日, 2024年 | 类别：产品

* * *

### [介绍上下文检索](https://www.anthropic.com/news/contextual-retrieval)[​](#introducing-contextual-retrieval "Direct link to introducing-contextual-retrieval")

Anthropic 引入了`上下文检索`，这是一种通过在嵌入前添加`块特定上下文`来显著改善 `RAG（检索增强生成）`系统的新技术。该方法与 `BM25` 结合时可减少 `49%` 的检索失败，与`重新排序`配对时可高达 `67%`，显著提高了 AI 应用程序知识库搜索的准确性。

9月19日, 2024年 | 类别：产品

* * *

### [Anthropic API 控制台中的工作区](https://www.anthropic.com/news/workspaces)[​](#workspaces-in-the-anthropic-api-console "Direct link to workspaces-in-the-anthropic-api-console")

Anthropic 在 `API 控制台`中推出了`工作区`功能，帮助开发者管理跨不同环境和用例的多个 Claude 部署。该功能提供`细粒度支出限制`、`资源组织`、`独立的速率限制管理`、`简化的访问控制`和`工作区级别的使用监控`，以实现更好的项目管理和安全性。

9月10日, 2024年 | 类别：产品

* * *

### [企业版 Claude](https://www.anthropic.com/news/claude-for-enterprise)[​](#claude-for-enterprise "Direct link to claude-for-enterprise")

Anthropic 宣布推出`企业版 Claude`，提供 `500K 上下文窗口`、增强的安全功能如 `SSO` 和`基于角色的权限`，以及用于代码库协作的原生 `GitHub` 集成。企业计划使组织能够安全地处理`内部知识`，同时保持数据保护，`GitLab` 和 `Midjourney` 等早期客户已在各种业务功能中使用它。

9月4日, 2024年 | 类别：产品

* * *

### [Salesforce 与 Anthropic 合作，使用 Claude 增强 Einstein 能力](https://www.anthropic.com/news/salesforce-partnership)[​](#salesforce-teams-up-with-anthropic-to-enhance-einstein-capabilities-with-claude "Direct link to salesforce-teams-up-with-anthropic-to-enhance-einstein-capabilities-with-claude")

`Salesforce` 与 Anthropic 合作，通过 `Amazon Bedrock` 将 Claude 模型（`3.5 Sonnet`、`Opus` 和 `Haiku`）集成到 `Einstein` 功能中。这一集成允许 Salesforce 客户将 Claude 用于`销售`、`营销`、`客户服务`和其他企业功能，同时通过 Salesforce 的 `Einstein Trust Layer` 和现有合规标准保持安全性。

9月3日, 2024年 | 类别：公告

* * *

* * *

## **2024年8月**[​](#august-2024 "Direct link to august-2024")

### [Artifacts 现已正式可用](https://www.anthropic.com/news/artifacts)[​](#artifacts-are-now-generally-available "Direct link to artifacts-are-now-generally-available")

`Artifacts` 对所有 `Claude.ai` 用户正式开放，涵盖 `免费`、`Pro` 和 `Team` 计划，包括移动端 `iOS` 和 `Android` 应用。该功能创建一个专门的工作空间，让用户可以立即查看、迭代和与 Claude 一起构建创意作品，从`代码片段`和`可视化`到`交互式原型`，自预览发布以来已创建了`数千万`个 Artifacts。

8月27日, 2024年 | 类别：公告

* * *

### [使用 Claude 进行提示缓存](https://www.anthropic.com/news/prompt-caching)[​](#prompt-caching-with-claude "Direct link to prompt-caching-with-claude")

Anthropic 为 Claude 引入了`提示缓存`，使开发者能够在 API 调用之间缓存常用上下文，成本降低高达 `90%`，延迟改善 `85%`。该功能对于`对话代理`、`编码助手`和`大文档处理`特别有效，缓存内容的成本仅为基础输入令牌价格的 `10%`，而缓存写入成本高出 `25%`。

8月14日, 2024年 | 类别：产品

* * *

### [扩展我们的模型安全漏洞赏金计划](https://www.anthropic.com/news/model-safety-bug-bounty)[​](#expanding-our-model-safety-bug-bounty-program "Direct link to expanding-our-model-safety-bug-bounty-program")

Anthropic 扩展了其`模型安全漏洞赏金计划`，重点识别可能绕过 AI 安全防护措施的`通用越狱攻击`，涉及 `CBRN` 和`网络安全`等高风险领域。这个`仅限邀请`的计划为新型漏洞提供高达 `15,000 美元`的奖励，并提供`早期访问`机会，在公开部署前测试下一代安全缓解系统。

8月8日, 2024年 | 类别：公告

* * *

### [Claude 现已在巴西可用](https://www.anthropic.com/news/claude-brazil)[​](#claude-is-now-available-in-brazil "Direct link to claude-is-now-available-in-brazil")

Anthropic 宣布 Claude 于 `2024 年 8 月 1 日`在`巴西`上线，通过 `Claude.ai`、`移动应用`和 `API` 提供 AI 助手服务。巴西用户可以免费使用 Claude，或订阅 `Pro`（`110 雷亚尔/月`）和 `Team` 计划（`165 雷亚尔/月`），享受增强的使用限额和功能。

8月1日, 2024年 | 类别：公告

* * *

* * *

## **2024年7月**[​](#july-2024 "Direct link to july-2024")

### [Anthropic 与 Menlo Ventures 合作推出 Anthology 基金](https://www.anthropic.com/news/anthropic-partners-with-menlo-ventures-to-launch-anthology-fund)[​](#anthropic-partners-with-menlo-ventures-to-launch-anthology-fund "Direct link to anthropic-partners-with-menlo-ventures-to-launch-anthology-fund")

Anthropic partnered with `Menlo Ventures` to launch the `$100 million` `Anthology Fund` on `July 17, 2024`, aimed at supporting startups building with Anthropic technology. The fund focuses on five key areas including AI infrastructure, healthcare applications, consumer AI solutions, and trust and safety tooling.

7月17日, 2024年 | 类别：公告

* * *

### [Claude Android 应用](https://www.anthropic.com/news/android-app)[​](#claude-android-app "Direct link to claude-android-app")

Anthropic 于 `2024 年 7 月 16 日`推出 `Claude Android 应用`，为 Android 用户免费提供 `Claude 3.5 Sonnet`。该应用提供与网页版和 iOS 版本的跨平台对话连续性、图像分析的视觉功能、多语言处理和复杂任务的高级推理能力。

7月16日, 2024年 | 类别：产品

* * *

### [在 Amazon Bedrock 中微调 Claude 3 Haiku](https://www.anthropic.com/news/fine-tune-claude-3-haiku)[​](#fine-tune-claude-3-haiku-in-amazon-bedrock "Direct link to fine-tune-claude-3-haiku-in-amazon-bedrock")

Anthropic 于 `2024 年 7 月 11 日`宣布在 `Amazon Bedrock` 中为 `Claude 3 Haiku` 提供微调功能，允许客户为专业业务任务定制模型。微调可以在特定领域任务上实现更好的性能、更快的速度和更低的成本，以及一致的品牌对齐格式。

7月11日, 2024年 | 类别：产品

* * *

### [在开发者控制台中评估提示](https://www.anthropic.com/news/evaluate-prompts)[​](#evaluate-prompts-in-the-developer-console "Direct link to evaluate-prompts-in-the-developer-console")

Anthropic 于 `2024 年 7 月 9 日`在开发者控制台中引入提示评估功能，简化 AI 应用开发。新工具包括由 `Claude 3.5 Sonnet` 驱动的自动提示生成、测试用例生成和并排输出比较功能。

7月9日, 2024年 | 类别：产品

* * *

### [开发第三方模型评估的新举措](https://www.anthropic.com/news/a-new-initiative-for-developing-third-party-model-evaluations)[​](#a-new-initiative-for-developing-third-party-model-evaluations "Direct link to a-new-initiative-for-developing-third-party-model-evaluations")

Anthropic 于 `2024 年 7 月 1 日`启动新计划，资助开发 AI 模型评估的第三方组织，解决评估生态系统有限的问题。该计划优先考虑 AI 安全级别评估、高级能力指标和评估基础设施开发。

7月1日, 2024年 | 类别：公告

* * *

* * *

## **2024年6月**[​](#june-2024 "Direct link to june-2024")

### [扩大政府部门对 Claude 的访问](https://www.anthropic.com/news/expanding-access-to-claude-for-government)[​](#expanding-access-to-claude-for-government "Direct link to expanding-access-to-claude-for-government")

Anthropic 于 `2024年6月26日` 扩大了政府用户对 Claude 的访问, 通过 `AWS Marketplace` 提供 `Claude 3 Haiku` 和 `Sonnet` 供 `美国情报界` 和 `AWS GovCloud` 使用. 此次扩展包括精心制定的合同例外条款 用于合法授权的外国情报分析 同时保持对虚假信息、武器设计和恶意网络行动的限制.

6月26日, 2024年 | 类别：公告

* * *

### [在项目中与 Claude 协作](https://www.anthropic.com/news/projects)[​](#collaborate-with-claude-on-projects "Direct link to collaborate-with-claude-on-projects")

Anthropic 在 `Claude.ai` 上为 `Pro` 和 `Team` 用户推出了 `项目` 功能 于 `2024年6月25日`，实现了与精选知识集的有组织协作 以及共享对话. 项目包括用于文档和代码的 `20万上下文窗口`, 定制响应的自定义指令，以及团队共享功能.

6月25日, 2024年 | 类别：产品

* * *

### [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)[​](#claude-35-sonnet "Direct link to claude-35-sonnet")

Anthropic 于 `2024年6月21日` 发布了 `Claude 3.5 Sonnet`, 在设定新的行业基准的同时，运行速度是 `Claude 3 Opus` 的 `两倍`. 该模型在研究生水平推理、编码能力方面表现出色 （在内部评估中解决了 `64%` 的问题）, 以及用于图表解释和文本转录的视觉能力.

6月21日, 2024年 | 类别：公告

* * *

### [AI系统红队测试的挑战](https://www.anthropic.com/news/challenges-in-red-teaming-ai-systems)[​](#challenges-in-red-teaming-ai-systems "Direct link to challenges-in-red-teaming-ai-systems")

Anthropic 于 `2024年6月12日` 发布了关于AI系统红队测试的见解, 详细介绍了包括专家领域测试在内的各种方法, 自动化红队测试和多模态评估. 文章概述了标准化红队测试实践的挑战 并提出了包括资助 `NIST` 在内的政策建议 用于技术标准和支持独立测试组织.

6月12日, 2024年 | 类别：政策

* * *

### [测试和缓解选举相关风险](https://www.anthropic.com/news/testing-and-mitigating-elections-related-risks)[​](#testing-and-mitigating-elections-related-risks "Direct link to testing-and-mitigating-elections-related-risks")

Anthropic 详细介绍了其测试和缓解选举相关风险的方法 于 `2024年6月6日`，结合政策漏洞测试 与外部专家和自动化评估. 公司实施了多项缓解措施，包括系统提示更新, 模型微调和政策完善 以提高准确性并适当引导至权威来源.

6月6日, 2024年 | 类别：政策

* * *

### [向加拿大推出 Claude](https://www.anthropic.com/news/introducing-claude-to-canada)[​](#introducing-claude-to-canada "Direct link to introducing-claude-to-canada")

Anthropic 于 `2024年6月5日` 向加拿大推出 Claude, 通过 Claude.ai、iOS应用、API和团队计划提供AI助手. 加拿大用户可以免费访问 Claude 或订阅 `Pro` 每月 `28加元`，`Team` 每用户每月 `42加元`, 可访问所有 Claude 3 模型并提高使用限制.

6月5日, 2024年 | 类别：公告

* * *

* * *

## **2024年5月**[​](#may-2024 "Direct link to may-2024")

### [Claude 现在可以使用工具](https://www.anthropic.com/news/tool-use-ga)[​](#claude-can-now-use-tools "Direct link to claude-can-now-use-tools")

Claude 的工具使用功能已全面推出 across the entire Claude 3 model family on `5月30日, 2024年`, 使 Claude 能够与外部工具和API交互 用于数据提取、API调用和数据库搜索等任务. 此功能包括流式支持、强制工具选择, 和图像兼容性, 显著扩展了 Claude 对开发人员和企业的实际应用.

5月30日, 2024年 | 类别：产品

* * *

### [Jay Kreps 被任命为 Anthropic 董事会成员](https://www.anthropic.com/news/jay-kreps-appointed-to-board-of-directors)[​](#jay-kreps-appointed-to-anthropics-board-of-directors "Direct link to jay-kreps-appointed-to-anthropics-board-of-directors")

`Confluent` 联合创始人兼CEO `Jay Kreps`, joined Anthropic's Board of Directors on `5月29日, 2024年`, 带来了构建和扩展科技公司的丰富经验 以及数据基础设施方面的专业知识. 他由 `长期利益信托` 任命 正值 Anthropic 准备进入下一个增长阶段, 同时 `Luke Muehlhauser` 退出董事会 专注于他在 `Open Philanthropy` 的工作.

5月29日, 2024年 | 类别：公告

* * *

### [金门大桥 Claude](https://www.anthropic.com/news/golden-gate-claude)[​](#golden-gate-claude "Direct link to golden-gate-claude")

`金门大桥 Claude` was a 24-hour research demonstration released on `5月23日, 2024年`, 展示了 Anthropic 在AI可解释性方面的突破 通过人为放大 Claude 的金门大桥特征 使其在所有回应中都痴迷地提及这座桥. 这展示了精确修改特定神经通路的能力 在AI模型中, 代表了在理解方面的重大进展 以及为安全目的控制AI行为的可能性.

5月23日, 2024年 | 类别：产品

* * *

### [Krishna Rao 加入 Anthropic 担任首席财务官](https://www.anthropic.com/news/krishna-rao-joins-anthropic)[​](#krishna-rao-joins-anthropic-as-chief-financial-officer "Direct link to krishna-rao-joins-anthropic-as-chief-financial-officer")

`Krishna Rao` 加入 Anthropic 担任首席财务官 on `5月21日, 2024年`, bringing nearly `20 years` 来自以下公司的战略财务经验 `Fanatics Commerce`、`Cedar` 和 `Airbnb` 他在那里帮助度过了疫情和IPO. 他在财务战略、资本配置方面的专业知识, 以及扩展高增长组织 将支持 Anthropic 的企业势头和国际扩张计划.

5月21日, 2024年 | 类别：公告

* * *

### [在开发者控制台中生成更好的提示](https://www.anthropic.com/news/prompt-generator)[​](#generate-better-prompts-in-the-developer-console "Direct link to generate-better-prompts-in-the-developer-console")

Anthropic 推出了提示生成器功能 in the developer console on `5月20日, 2024年`, 自动创建生产就绪的提示模板 使用思维链推理和角色设置等最佳实践. 该工具帮助新手和经验丰富的提示工程师 基于任务描述生成有效、精确的提示, 显著减少开发时间并提高输出质量.

5月20日, 2024年 | 类别：产品

* * *

### [对我们负责任扩展政策的反思](https://www.anthropic.com/news/reflections-on-our-responsible-scaling-policy)[​](#reflections-on-our-responsible-scaling-policy "Direct link to reflections-on-our-responsible-scaling-policy")

Anthropic 于 `2024 年 5 月 20 日`发布了实施负责任扩展政策的反思，概述了五项关键承诺，包括建立`红线能力`、进行前沿风险评估和开发 `ASL-3` 安全标准。这篇文章详细介绍了操作化政策的经验教训，包括在威胁建模、评估方法学和安全措施所需大量组织投资方面的挑战。

5月20日, 2024年 | 类别：政策

* * *

### [Mike Krieger 加入 Anthropic 担任首席产品官](https://www.anthropic.com/news/mike-krieger-joins-anthropic)[​](#mike-krieger-joins-anthropic-as-chief-product-officer "Direct link to mike-krieger-joins-anthropic-as-chief-product-officer")

`Mike Krieger`, co-founder and former CTO of `Instagram`, joined Anthropic as Chief Product Officer on `5月15日, 2024年`, bringing experience scaling platforms to over a billion users and building `Artifact`, a personalized news app. He will oversee product engineering, management, and design efforts as Anthropic expands its enterprise applications and brings Claude to a wider audience.

5月15日, 2024年 | 类别：公告

* * *

### [Claude 现已在欧洲可用](https://www.anthropic.com/news/claude-europe)[​](#claude-is-now-available-in-europe "Direct link to claude-is-now-available-in-europe")

Claude 于 `2024 年 5 月 14 日`在欧洲全面上线，包括 Claude.ai、iOS 应用和 Team 计划，继早期欧洲 Claude API 发布之后。此次扩展为欧洲用户提供了 Claude 强大的多语言能力，支持法语、德语、西班牙语和意大利语，`Claude Pro` 价格为`每月 18 欧元 + 增值税`，`Team` 计划为`每用户每月 28 欧元 + 增值税`。

5月14日, 2024年 | 类别：公告

* * *

### [更新我们的使用政策](https://www.anthropic.com/news/updating-our-usage-policy)[​](#updating-our-usage-policy "Direct link to updating-our-usage-policy")

Anthropic 于 `2024 年 5 月 10 日`更新了其使用政策（原可接受使用政策），变更于 `2024 年 6 月 6 日`生效，将指南简化为`通用使用标准`，并明确了对选举干扰和错误信息的限制。更新还增加了对医疗决策等高风险用例的要求，通过具有安全措施的组织扩大了未成年人的访问权限，并加强了针对生物识别分析和政府审查的隐私保护。

5月10日, 2024年 | 类别：公告

* * *

### [介绍 Claude 团队计划和 iOS 应用](https://www.anthropic.com/news/team-plan-and-ios)[​](#introducing-the-claude-team-plan-and-ios-app "Direct link to introducing-the-claude-team-plan-and-ios-app")

Anthropic launched the Claude `Team` plan (`$30 per user per month`, minimum `5 seats`) and `iOS app` on `5月1日, 2024年`, providing teams with increased usage, access to the full Claude 3 model family, and administrative tools. The free `iOS app` offers seamless syncing with web chats, vision capabilities for photo analysis, and mobile access to Claude's frontier intelligence capabilities.

5月1日, 2024年 | 类别：产品

* * *

* * *

## **2024年4月**[​](#april-2024 "Direct link to april-2024")

### [在儿童安全原则上达成一致](https://www.anthropic.com/news/child-safety-principles)[​](#aligning-on-child-safety-principles "Direct link to aligning-on-child-safety-principles")

Anthropic committed to child safety principles on `April 23, 2024`, as part of a `Safety by Design` initiative led by `Thorn` and `All Tech Is Human` to prevent AI-generated child sexual abuse material (`AIG-CSAM`). The commitment includes specific measures across development, deployment, and maintenance phases, such as responsibly sourcing training data, detecting abusive content, and reporting violations to `NCMEC`.

4月23日, 2024年 | 类别：公告

* * *

* * *

## **2024年3月**[​](#march-2024 "Direct link to march-2024")

### [第三方测试作为 AI 政策的关键组成部分](https://www.anthropic.com/news/third-party-testing)[​](#third-party-testing-as-a-key-ingredient-of-ai-policy "Direct link to third-party-testing-as-a-key-ingredient-of-ai-policy")

Anthropic 于 `2024 年 3 月 25 日`发布政策立场，主张第三方测试对 AI 政策至关重要，认为前沿 AI 系统需要独立监督来验证安全声明并防止滥用。该公司概述了此类测试机制的运作方式，包括自动化初步筛选后进行专家人工评估，并强调政府需要为测试基础设施和评估能力提供资金。

3月25日, 2024年 | 类别：政策

* * *

### [Anthropic、AWS 和 Accenture 合作为企业构建可信解决方案](https://www.anthropic.com/news/accenture-aws-anthropic)[​](#anthropic-aws-and-accenture-team-up-to-build-trusted-solutions-for-enterprises "Direct link to anthropic-aws-and-accenture-team-up-to-build-trusted-solutions-for-enterprises")

Anthropic 宣布与 `AWS` 和 `埃森哲 (Accenture)` 合作，帮助企业负责任地部署生成式 AI 解决方案，特别是在受监管行业。超过 `1,400` 名埃森哲工程师将接受培训，成为在 AWS 上使用 Anthropic 模型的专家，提供从概念到生产的端到端支持，同时保持客户数据的私密和安全。

3月20日, 2024年 | 类别：公告

* * *

### [Vertex AI 上的 Claude 3 模型](https://www.anthropic.com/news/google-vertex-general-availability)[​](#claude-3-models-on-vertex-ai "Direct link to claude-3-models-on-vertex-ai")

`Claude 3 Haiku` 和 `Claude 3 Sonnet` 在 `谷歌云 Vertex AI` 平台上正式推出，使企业能够使用 Anthropic 最先进的模型以及谷歌云的基础设施和工具。这一合作使企业能够将数据保留在现有的云环境中，同时简化数据治理并降低运营成本。

3月19日, 2024年 | 类别：公告

* * *

### [Claude 3 Haiku：我们迄今为止最快的模型](https://www.anthropic.com/news/claude-3-haiku)[​](#claude-3-haiku-our-fastest-model-yet "Direct link to claude-3-haiku-our-fastest-model-yet")

Anthropic 发布了 `Claude 3 Haiku`，这是其智能级别中最快且最实惠的模型，每秒处理 `21K 令牌`并具有强大的视觉能力。`Haiku` 在大多数工作负载上比同类产品`快三倍`，成本显著更低，使企业能够以其性能层级中其他模型`一半的成本`分析大量文档，如季度申报或法律案件。

3月13日, 2024年 | 类别：公告

* * *

### [介绍下一代 Claude](https://www.anthropic.com/news/claude-3-family)[​](#introducing-the-next-generation-of-claude "Direct link to introducing-the-next-generation-of-claude")

Anthropic introduced the `Claude 3` model family, setting new industry benchmarks with three models: `Haiku`, `Sonnet`, and `Opus`, each offering different balances of intelligence, speed, and cost. `Claude 3 Opus` outperforms peers on most evaluation benchmarks and exhibits near-human comprehension, while all models feature sophisticated vision capabilities, `200K context windows`, improved accuracy with `2x fewer hallucinations`, and significantly fewer unnecessary refusals.

3月4日, 2024年 | 类别：公告

* * *

* * *

## **2024年2月**[​](#february-2024 "Direct link to february-2024")

### [面向商业性能的提示工程](https://www.anthropic.com/news/prompt-engineering-for-business-performance)[​](#prompt-engineering-for-business-performance "Direct link to prompt-engineering-for-business-performance")

Anthropic 发布了关于提升业务性能的提示工程指导，强调有效的提示如何提高 Claude 的准确性、一致性和成本效益，同时降低幻觉率。文章分享了三种关键技术：`逐步推理`、带示例的`少样本提示`和用于复杂任务的`提示链`。

2月29日, 2024年 | 类别：产品

* * *

### [为 2024 年全球选举做准备](https://www.anthropic.com/news/preparing-for-global-elections-in-2024)[​](#preparing-for-global-elections-in-2024 "Direct link to preparing-for-global-elections-in-2024")

Anthropic 概述了他们为 `2024` 年全球选举的准备情况，实施了禁止使用 Claude 进行政治竞选和游说的政策，同时进行有针对性的红队测试以检测与选举相关的滥用。该公司开发了自动系统来检测错误信息和影响操作，并为美国用户引入重定向系统，将投票问题引导到 `TurboVote` 等权威来源。

2月16日, 2024年 | 类别：政策

* * *

* * *

## **2023年12月**[​](#december-2023 "Direct link to december-2023")

### [扩展法律保护和改进我们的 API](https://www.anthropic.com/news/expanded-legal-protections-api-improvements)[​](#expanded-legal-protections-and-improvements-to-our-api "Direct link to expanded-legal-protections-and-improvements-to-our-api")

Anthropic introduced new Commercial Terms of Service with expanded copyright indemnity protection and launched the beta `Messages API` for improved developer experience. The updated terms allow customers to retain ownership of outputs and provide legal protection against copyright infringement claims, with Anthropic defending customers and paying for settlements or judgments.

12月19日, 2023年 | 类别：公告

* * *

### [Claude 2.1 的长上下文提示](https://www.anthropic.com/news/claude-2-1-prompting)[​](#long-context-prompting-for-claude-21 "Direct link to long-context-prompting-for-claude-21")

Anthropic 发布了关于 `Claude 2.1` 长上下文提示的见解，揭示虽然该模型在其 `200K 令牌`上下文窗口中具有出色的回忆能力，但可能不愿意回答基于文档中看起来不合适的单个句子的问题。添加简单的提示`这是上下文中最相关的句子：`将 `Claude 2.1` 在检索任务上的性能从 `27%` 提高到 `98%`。

12月6日, 2023年 | 类别：产品

* * *

* * *

## **2023年11月**[​](#november-2023 "Direct link to november-2023")

### [介绍 Claude 2.1](https://www.anthropic.com/news/claude-2-1)[​](#introducing-claude-21 "Direct link to introducing-claude-21")

Anthropic launched `Claude 2.1` with significant improvements including an industry-leading `200K token` context window (equivalent to `500 pages`), a `2x decrease` in hallucination rates, and new features like system prompts and beta tool use functionality. The model demonstrates `30%` fewer incorrect answers and `3-4x` lower rates of mistakenly concluding documents support particular claims.

11月21日, 2023年 | 类别：产品

* * *

### [Thoughts on the US Executive Order, G7 Code of Conduct, and Bletchley Park Summit](https://www.anthropic.com/news/policy-recap-q4-2023)[​](#thoughts-on-the-us-executive-order-g7-code-of-conduct-and-bletchley-park-summit "Direct link to thoughts-on-the-us-executive-order-g7-code-of-conduct-and-bletchley-park-summit")

Anthropic 分享了他们对三项重大 AI 政策发展的看法：`美国 AI 行政命令`、`G7 国际行为准则`和`英国布莱切利公园 AI 安全峰会`。该公司赞扬行政命令对 `NIST` 和`国家 AI 研究资源`的关注，支持 `G7 行为准则`为前沿 AI 公司设定重要基线，并欢迎`布莱切利宣言`的国际合作。

11月5日, 2023年 | 类别：政策

* * *

### [Dario Amodei’s prepared remarks from the AI Safety Summit on Anthropic’s Responsible Scaling Policy](https://www.anthropic.com/news/uk-ai-safety-summit)[​](#dario-amodeis-prepared-remarks-from-the-ai-safety-summit-on-anthropics-responsible-scaling-policy "Direct link to dario-amodeis-prepared-remarks-from-the-ai-safety-summit-on-anthropics-responsible-scaling-policy")

`Dario Amodei` presented Anthropic's `Responsible Scaling Policy (RSP)` at the `UK AI Safety Summit`, outlining their `AI Safety Levels (ASL)` system modeled after biological safety protocols. The RSP includes if-then commitments where dangerous AI capabilities trigger specific safety requirements, with `ASL-3` requiring strong security measures and perfect safety performance, and `ASL-4` addressing autonomous AI risks.

11月1日, 2023年 | 类别：政策

* * *

* * *

## **2023年9月**[​](#september-2023 "Direct link to september-2023")

### [Claude on Amazon Bedrock now available to every AWS customer](https://www.anthropic.com/news/amazon-bedrock-general-availability)[​](#claude-on-amazon-bedrock-now-available-to-every-aws-customer "Direct link to claude-on-amazon-bedrock-now-available-to-every-aws-customer")

Claude 在 `Amazon Bedrock` 上对所有 AWS 客户正式推出，提供对基础模型的安全云访问，并支持开发生成式 AI 应用。公告强调了即将推出的 `Amazon Bedrock 代理`功能，该功能允许 Claude 编排 API 调用并执行复杂的多步骤任务。

9月28日, 2023年 | 类别：公告

* * *

### [Expanding access to safer AI with Amazon](https://www.anthropic.com/news/anthropic-amazon)[​](#expanding-access-to-safer-ai-with-amazon "Direct link to expanding-access-to-safer-ai-with-amazon")

Anthropic 宣布与`亚马逊`达成战略合作伙伴关系，涉及高达 `40 亿美元`的投资，使 `AWS` 成为他们的主要云提供商，并在 `Amazon Bedrock` 上扩展 `Claude 2` 的可用性。此次合作包括访问 `AWS Trainium` 和 `Inferentia` 芯片进行模型训练、为企业提供安全的模型定制功能，以及在亚马逊各业务中的集成，同时通过`长期利益信托`保持 Anthropic 的治理结构。

9月25日, 2023年 | 类别：公告

* * *

### [Prompt engineering for Claude's long context window](https://www.anthropic.com/news/prompting-long-context)[​](#prompt-engineering-for-claudes-long-context-window "Direct link to prompt-engineering-for-claudes-long-context-window")

Anthropic 发布了关于 Claude `100,000 令牌`上下文窗口提示工程技术的研究，展示如何最大化从长文档中回忆信息。研究发现，使用参考引用提取和提供上下文示例显著提高了 Claude 在多选题上的表现，当这些技术应用于包含 `70K-95K 令牌`的文档时，`Claude Instant 1.2` 显示出实质性收益。

9月23日, 2023年 | 类别：产品

* * *

### [Anthropic's Responsible Scaling Policy](https://www.anthropic.com/news/anthropics-responsible-scaling-policy)[​](#anthropics-responsible-scaling-policy "Direct link to anthropics-responsible-scaling-policy")

Anthropic 发布了他们的`负责任扩展政策 (RSP)`，建立了仿照生物安全标准的 `AI 安全级别 (ASL)` 框架，以管理日益强大的 AI 系统的灾难性风险。该政策为不同能力级别定义了安全要求，`ASL-2` 涵盖当前模型如 `Claude`，`ASL-3` 需要增强的安全和红队测试标准，并创建了一个框架，激励解决安全问题以解锁进一步的 AI 扩展。

9月19日, 2023年 | 类别：公告

* * *

### [The Long-Term Benefit Trust](https://www.anthropic.com/news/the-long-term-benefit-trust)[​](#the-long-term-benefit-trust "Direct link to the-long-term-benefit-trust")

Anthropic introduced the `Long-Term Benefit Trust (LTBT)`, a governance structure featuring `five` independent trustees who will gradually gain authority to elect a majority of Anthropic's board within `four years`. This experimental corporate governance model aims to balance stockholder interests with public benefit by ensuring board accountability to trustees with expertise in AI safety, national security, and public policy, while maintaining the company's mission of developing AI for humanity's long-term benefit.

9月19日, 2023年 | 类别：公告

* * *

### [Anthropic partners with BCG](https://www.anthropic.com/news/anthropic-bcg)[​](#anthropic-partners-with-bcg "Direct link to anthropic-partners-with-bcg")

Anthropic 与`波士顿咨询集团 (BCG)` 合作，将 Claude 带给全球企业客户，专注于在知识管理、市场研究和业务分析等用例中负责任地部署 AI。此次合作利用 BCG 的咨询专业知识，帮助组织在保持道德标准的同时战略性地实施 AI，BCG 也在内部使用 Claude 进行研究综合和客户洞察。

9月14日, 2023年 | 类别：公告

* * *

### [Introducing Claude Pro](https://www.anthropic.com/news/claude-pro)[​](#introducing-claude-pro "Direct link to introducing-claude-pro")

Anthropic 推出了 `Claude Pro`，这是一个付费订阅计划，在`美国`为`每月 20 美元`，在`英国`为`每月 18 英镑`，提供 `Claude 2` `5 倍`的使用量。该服务提供高流量时段的优先访问权、新功能的早期访问权和显著扩展的消息限制，使用户能够处理更复杂的任务，如研究论文总结、合同分析和扩展编码项目。

9月7日, 2023年 | 类别：公告

* * *

* * *

## **2023年8月**[​](#august-2023 "Direct link to august-2023")

### [Claude 2 on Amazon Bedrock](https://www.anthropic.com/news/claude-2-amazon-bedrock)[​](#claude-2-on-amazon-bedrock "Direct link to claude-2-on-amazon-bedrock")

`Claude 2` became available on `Amazon Bedrock`, Amazon's fully managed foundation model service, enabling enterprises to build generative AI applications with enhanced security and scalability. Early adopters include `LexisNexis` using `Claude 2` for legal AI capabilities, `Lonely Planet` for travel planning with `80%` cost reduction in itinerary generation, and `Ricoh USA` for AI-driven operations while maintaining `HIPAA` and `SOC II` compliance.

8月23日, 2023年 | 类别：产品

* * *

### [SKT Partnership Announcement](https://www.anthropic.com/news/skt-partnership-announcement)[​](#skt-partnership-announcement "Direct link to skt-partnership-announcement")

`SK Telecom (SKT)` became both a commercial partner and strategic investor in Anthropic with an additional `$100 million` investment, collaborating to develop a fine-tuned large language model optimized for telecommunications applications. The partnership will create a multilingual model supporting `Korean`, `English`, `Japanese`, and `Spanish` for telco use cases including customer service, marketing, and sales, leveraging SKT's domain expertise to customize Claude for the telecommunications industry.

8月15日, 2023年 | 类别：公告

* * *

### [Releasing Claude Instant 1.2](https://www.anthropic.com/news/releasing-claude-instant-1-2)[​](#releasing-claude-instant-12 "Direct link to releasing-claude-instant-12")

Anthropic 发布了 `Claude Instant 1.2`，这是他们更快、更低成本模型的更新版本，包含了来自 `Claude 2` 的改进，同时保持速度和价格优势。新版本在数学（`GSM8K` 上 `86.7%` 对比 `80.9%`）、编码（`Codex` 上 `58.7%` 对比 `52.8%`）、推理能力和安全性方面显示出显著改进，减少了幻觉并更好地抵抗越狱攻击，同时生成更长和更结构化的响应。

8月9日, 2023年 | 类别：公告

* * *

* * *

## **2023年7月**[​](#july-2023 "Direct link to july-2023")

### [Frontier Threats Red Teaming for AI Safety](https://www.anthropic.com/news/frontier-threats-red-teaming-for-ai-safety)[​](#frontier-threats-red-teaming-for-ai-safety "Direct link to frontier-threats-red-teaming-for-ai-safety")

Anthropic conducted frontier threats red teaming research focusing on biological risks, spending `150+ hours` with biosecurity experts to evaluate Claude's potential for generating harmful biological information. The study found that current frontier models can produce expert-level knowledge that could accelerate bad actors' efforts, with risks potentially materializing in `2-3 years`, but also identified effective mitigations including `Constitutional AI` training and classifier-based filters that substantially reduce these risks.

7月26日, 2023年 | 类别：公告

* * *

### [Frontier Model Security](https://www.anthropic.com/news/frontier-model-security)[​](#frontier-model-security "Direct link to frontier-model-security")

Anthropic 发布了他们的前沿模型安全方法，建议使用`双方控制系统`和安全软件开发实践（`NIST SSDF` 和 `SLSA` 标准）来保护先进的 AI 模型。该公司主张将前沿 AI 视为关键基础设施，需要增强的网络安全措施、类似金融服务的公私合作，以及政府采购要求，以确保全行业采用强大的安全实践。

7月25日, 2023年 | 类别：公告

* * *

### [Claude 2](https://www.anthropic.com/news/claude-2)[​](#claude-2 "Direct link to claude-2")

Anthropic launched `Claude 2`, their most advanced model featuring improved performance across coding (`71.2%` on `Codex HumanEval`), math (`88.0%` on `GSM8k`), and reasoning, with a `100,000 token` context window enabling processing of entire books or extensive documentation. The model scored `76.5%` on the `Bar exam` and above the `90th percentile` on `GRE` reading/writing, while being `2x better` at harmless responses, and is available via API and the new `claude.ai` chat interface in the `US` and `UK`.

7月11日, 2023年 | 类别：公告

* * *

* * *

## **2023年6月**[​](#june-2023 "Direct link to june-2023")

### [Charting a Path to AI Accountability](https://www.anthropic.com/news/charting-a-path-to-ai-accountability)[​](#charting-a-path-to-ai-accountability "Direct link to charting-a-path-to-ai-accountability")

Anthropic 向 `NTIA` 提交了关于 AI 问责制的建议，提出了评估先进 AI 系统的综合框架。建议包括资助更好的评估、基于模型能力创建风险响应评估、建立大型 AI 训练的预注册、赋予第三方审计员权力、强制外部红队测试、推进可解释性研究，以及通过反垄断清晰度促进行业在 AI 安全方面的合作。

6月13日, 2023年 | 类别：公告

* * *

* * *

## **2023年5月**[​](#may-2023 "Direct link to may-2023")

### [Anthropic Raises $450 Million in Series C Funding to Scale Reliable AI Products](https://www.anthropic.com/news/anthropic-series-c)[​](#anthropic-raises-450-million-in-series-c-funding-to-scale-reliable-ai-products "Direct link to anthropic-raises-450-million-in-series-c-funding-to-scale-reliable-ai-products")

Anthropic 在 `C 轮`融资中筹集了 `4.5 亿美元`，由 `Spark Capital` 领投，`谷歌`、`Salesforce Ventures`、`Sound Ventures` 和 `Zoom Ventures` 参投。这笔资金将支持 Claude 的持续开发和 AI 安全研究，包括 `100K 上下文窗口`等新功能，同时扩大他们的产品供应并支持企业负责任地部署 Claude。

5月23日, 2023年 | 类别：公告

* * *

### [Zoom Partnership and Investment in Anthropic](https://www.anthropic.com/news/zoom-partnership-and-investment)[​](#zoom-partnership-and-investment-in-anthropic "Direct link to zoom-partnership-and-investment-in-anthropic")

Anthropic 宣布与 `Zoom` 合作，Claude 将被集成到 Zoom 的产品中，从 `Zoom 联络中心`产品组合开始，以改善客户体验和代理人性能。`Zoom Ventures` 作为此次合作的一部分也对 Anthropic 进行了投资，反映了他们在构建以客户为中心、具有信任和安全基础的 AI 产品方面的共同愿景。

5月16日, 2023年 | 类别：公告

* * *

### [Introducing 100K Context Windows](https://www.anthropic.com/news/100k-context-windows)[​](#introducing-100k-context-windows "Direct link to introducing-100k-context-windows")

Anthropic 将 Claude 的上下文窗口从 `9K` 扩展到 `100K 令牌`（约 `75,000 词`），允许用户提交数百页文档进行分析。这一突破使 Claude 能够在`不到一分钟`内消化和分析大量文本，支持财务报表分析、法律文件审查和代码库修改等用例。

5月11日, 2023年 | 类别：公告

* * *

### [Claude’s Constitution](https://www.anthropic.com/news/claudes-constitution)[​](#claudes-constitution "Direct link to claudes-constitution")

Anthropic 发布了关于 `Claude 宪法`的详细信息，解释了他们的`宪法 AI` 方法，该方法使用明确的原则而非隐含的人类反馈来指导 AI 行为。该宪法来源包括`联合国人权宣言`、平台指南和 AI 安全研究，原则涵盖了有用性、无害性、诚实性以及对不同文化视角下人类价值观的尊重。

5月9日, 2023年 | 类别：公告

* * *

* * *

## **2023年4月**[​](#april-2023 "Direct link to april-2023")

### [Partnering with Scale to Bring Generative AI to Enterprises](https://www.anthropic.com/news/partnering-with-scale)[​](#partnering-with-scale-to-bring-generative-ai-to-enterprises "Direct link to partnering-with-scale-to-bring-generative-ai-to-enterprises")

Anthropic 与 `Scale` 合作，通过 Scale 强大的部署和管理平台将 Claude 带给企业客户。此次合作提供企业级安全性、专家提示工程、模型验证服务和专有数据源连接器，使企业能够大规模构建和部署使用 Claude 的生成式 AI 应用。

4月26日, 2023年 | 类别：公告

* * *

### [An AI Policy Tool for Today: Ambitiously Invest in NIST](https://www.anthropic.com/news/an-ai-policy-tool-for-today-ambitiously-invest-in-nist)[​](#an-ai-policy-tool-for-today-ambitiously-invest-in-nist "Direct link to an-ai-policy-tool-for-today-ambitiously-invest-in-nist")

Anthropic 主张联邦政府对 `NIST` 进行雄心勃勃的投资，以支持 AI 测量和标准工作，提议增加 `1500 万美元`的资金。该公司认为，NIST 一个世纪的测量专业知识使其成为开发 AI 评估标准的自然选择，这些标准是有效 AI 监管和公众对 AI 系统信任的必要先决条件。

4月20日, 2023年 | 类别：公告

* * *

* * *

## **2023年3月**[​](#march-2023 "Direct link to march-2023")

### [Claude, now in Slack](https://www.anthropic.com/news/claude-now-in-slack)[​](#claude-now-in-slack "Direct link to claude-now-in-slack")

Anthropic launched the `Claude App for Slack` in `beta`, allowing teams to use Claude as a virtual teammate for summarizing threads, answering questions, and various productivity tasks. Claude can be accessed through channel mentions or direct messages, with Anthropic emphasizing that it only sees messages where explicitly mentioned and doesn't use this data for model training.

3月30日, 2023年 | 类别：公告

* * *

### [Introducing Claude](https://www.anthropic.com/news/introducing-claude)[​](#introducing-claude "Direct link to introducing-claude")

Anthropic officially introduced `Claude`, their next-generation AI assistant based on `Constitutional AI` research, after testing with partners like `Notion`, `Quora`, and `DuckDuckGo`. Claude offers two versions (`Claude` and `Claude Instant`) and is designed to be helpful, honest, and harmless, with early customers reporting it's less likely to produce harmful outputs and easier to steer than alternatives.

3月14日, 2023年 | 类别：公告

* * *

* * *

## **2023年2月**[​](#february-2023 "Direct link to february-2023")

### [Anthropic Partners with Google Cloud](https://www.anthropic.com/news/anthropic-partners-with-google-cloud)[​](#anthropic-partners-with-google-cloud "Direct link to anthropic-partners-with-google-cloud")

Anthropic 选择 `谷歌云`作为其云提供商，以支持下一阶段将 Claude 扩展并部署给更大的受众。此次合作使 Anthropic 能够利用谷歌云的 `GPU` 和 `TPU` 集群进行训练、扩展和部署 AI 系统，为他们可靠和可解释的 AI 开发目标提供所需的基础设施性能。

2月3日, 2023年 | 类别：公告

* * *

* * *

## **2022年4月**[​](#april-2022 "Direct link to april-2022")

### [Anthropic Raises Series B to build steerable, interpretable, robust AI systems](https://www.anthropic.com/news/anthropic-raises-series-b-to-build-safe-reliable-ai)[​](#anthropic-raises-series-b-to-build-steerable-interpretable-robust-ai-systems "Direct link to anthropic-raises-series-b-to-build-steerable-interpretable-robust-ai-systems")

Anthropic 在 `B 轮`融资中筹集了 `5.8 亿美元`，由 `Sam Bankman-Fried` 领投，用于构建大规模实验基础设施来探索 AI 安全属性。这笔资金支持研究使 AI 系统更可控、可解释和稳健，基于他们在语言模型可解释性和与人类偏好对齐方面的前期工作。

4月29日, 2022年 | 类别：公告

* * *

* * *

## **2021年5月**[​](#may-2021 "Direct link to may-2021")

### [Anthropic raises $124 million to build more reliable, general AI systems](https://www.anthropic.com/news/anthropic-raises-124-million-to-build-more-reliable-general-ai-systems)[​](#anthropic-raises-124-million-to-build-more-reliable-general-ai-systems "Direct link to anthropic-raises-124-million-to-build-more-reliable-general-ai-systems")

Anthropic 在 `A 轮`融资中筹集了 `1.24 亿美元`，由 `Jaan Tallinn` 领投，以支持他们构建可靠和可控 AI 系统的研究路线图。由兄妹 `Dario` 和 `Daniela Amodei` 领导的创始团队计划专注于计算密集型研究，开发更可解释、更稳健且更好地与人类反馈整合的大规模 AI 系统。

5月28日, 2021年 | 类别：公告

* * *

* * *
