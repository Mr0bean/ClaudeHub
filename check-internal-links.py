#!/usr/bin/env python3
import os
import re
import glob
from urllib.parse import urlparse

def get_all_md_files(docs_dir):
    """è·å–æ‰€æœ‰ markdown æ–‡ä»¶"""
    return glob.glob(os.path.join(docs_dir, "*.md"))

def get_existing_pages(docs_dir):
    """è·å–æ‰€æœ‰å­˜åœ¨çš„é¡µé¢ï¼ˆä¸åŒ…æ‹¬æ‰©å±•åï¼‰"""
    md_files = get_all_md_files(docs_dir)
    pages = set()
    
    for file_path in md_files:
        filename = os.path.basename(file_path)
        if filename.endswith('.md'):
            page_name = filename[:-3]  # ç§»é™¤ .md æ‰©å±•å
            pages.add(page_name)
    
    # æ·»åŠ ä¸€äº›ç‰¹æ®Šé¡µé¢
    pages.add('index')  # README.md å¯¹åº” index
    pages.add('')  # é¦–é¡µ
    
    return pages

def extract_internal_links(content):
    """æå–å†…å®¹ä¸­çš„å†…éƒ¨é“¾æ¥"""
    # åŒ¹é… markdown é“¾æ¥ [text](url) å’Œ [text](/url)
    link_pattern = r'\[([^\]]*)\]\(([^)]+)\)'
    links = re.findall(link_pattern, content)
    
    internal_links = []
    for text, url in links:
        # è·³è¿‡å¤–éƒ¨é“¾æ¥
        if url.startswith('http://') or url.startswith('https://'):
            continue
        
        # è·³è¿‡é”šç‚¹é“¾æ¥
        if url.startswith('#'):
            continue
            
        # è·³è¿‡ mailto é“¾æ¥
        if url.startswith('mailto:'):
            continue
            
        internal_links.append((text, url))
    
    return internal_links

def normalize_url(url):
    """æ ‡å‡†åŒ– URL"""
    # ç§»é™¤å¼€å¤´çš„ /
    if url.startswith('/'):
        url = url[1:]
    
    # ç§»é™¤é”šç‚¹
    if '#' in url:
        url = url.split('#')[0]
    
    # ç§»é™¤ .html æ‰©å±•å
    if url.endswith('.html'):
        url = url[:-5]
    
    return url

def check_file_links(file_path, existing_pages):
    """æ£€æŸ¥å•ä¸ªæ–‡ä»¶ä¸­çš„é“¾æ¥"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    internal_links = extract_internal_links(content)
    broken_links = []
    
    for text, url in internal_links:
        normalized_url = normalize_url(url)
        
        # ç‰¹æ®Šå¤„ç†ï¼šç©ºå­—ç¬¦ä¸²æŒ‡å‘é¦–é¡µ
        if normalized_url == '' or normalized_url == 'index':
            continue
            
        if normalized_url not in existing_pages:
            broken_links.append((text, url, normalized_url))
    
    return broken_links

def suggest_fix(broken_url, existing_pages):
    """ä¸ºæŸåçš„é“¾æ¥å»ºè®®ä¿®å¤æ–¹æ¡ˆ"""
    # å°è¯•æ‰¾åˆ°ç›¸ä¼¼çš„é¡µé¢
    suggestions = []
    
    for page in existing_pages:
        if page == '':
            continue
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯éƒ¨åˆ†åŒ¹é…
        if broken_url in page or page in broken_url:
            suggestions.append(page)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸ä¼¼çš„åç§°
        broken_words = set(broken_url.replace('-', ' ').split())
        page_words = set(page.replace('-', ' ').split())
        
        # å¦‚æœæœ‰å…±åŒè¯æ±‡ï¼Œå¯èƒ½æ˜¯ç›¸å…³é¡µé¢
        if broken_words & page_words:
            suggestions.append(page)
    
    return suggestions[:3]  # è¿”å›æœ€å¤š3ä¸ªå»ºè®®

def main():
    docs_dir = '/Users/ruanchuhao/Downloads/Codes/å…¶ä»–/claudelogTranslate/final-site/docs'
    
    print("ğŸ” æ£€æŸ¥ç«™å†…é“¾æ¥...")
    
    # è·å–æ‰€æœ‰å­˜åœ¨çš„é¡µé¢
    existing_pages = get_existing_pages(docs_dir)
    print(f"ğŸ“„ å‘ç° {len(existing_pages)} ä¸ªé¡µé¢")
    
    # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶çš„é“¾æ¥
    md_files = get_all_md_files(docs_dir)
    total_broken = 0
    files_with_broken_links = 0
    
    for file_path in sorted(md_files):
        filename = os.path.basename(file_path)
        broken_links = check_file_links(file_path, existing_pages)
        
        if broken_links:
            files_with_broken_links += 1
            print(f"\nâŒ {filename}:")
            
            for text, original_url, normalized_url in broken_links:
                total_broken += 1
                print(f"   ğŸ”— [{text}]({original_url})")
                print(f"      âœ æ ‡å‡†åŒ–å: {normalized_url}")
                
                # å»ºè®®ä¿®å¤æ–¹æ¡ˆ
                suggestions = suggest_fix(normalized_url, existing_pages)
                if suggestions:
                    print(f"      ğŸ’¡ å»ºè®®ä¿®å¤ä¸º: {', '.join(suggestions)}")
                else:
                    print(f"      âš ï¸  æœªæ‰¾åˆ°ç›¸ä¼¼é¡µé¢")
    
    print(f"\nğŸ“Š æ£€æŸ¥å®Œæˆ:")
    print(f"   â€¢ æ€»æ–‡ä»¶æ•°: {len(md_files)}")
    print(f"   â€¢ æœ‰é—®é¢˜çš„æ–‡ä»¶: {files_with_broken_links}")
    print(f"   â€¢ æŸåçš„é“¾æ¥æ€»æ•°: {total_broken}")
    
    if total_broken == 0:
        print("âœ… æ‰€æœ‰ç«™å†…é“¾æ¥éƒ½æ˜¯æœ‰æ•ˆçš„ï¼")
    else:
        print(f"âŒ å‘ç° {total_broken} ä¸ªæŸåçš„ç«™å†…é“¾æ¥éœ€è¦ä¿®å¤")

if __name__ == "__main__":
    main()