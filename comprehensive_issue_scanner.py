#!/usr/bin/env python3
"""
Comprehensive Issue Scanner for VuePress Site
Scans for all potential problems in the translated documentation
"""

import re
import json
from pathlib import Path
from collections import defaultdict
import os

class ComprehensiveIssueScanner:
    def __init__(self, docs_dir="final-site/docs"):
        self.docs_dir = Path(docs_dir)
        self.issues = defaultdict(list)
        self.stats = {
            'total_files': 0,
            'files_scanned': 0,
            'total_issues': 0
        }
    
    def scan_all(self):
        """Run all scans"""
        print("ğŸ” å¼€å§‹å…¨é¢é—®é¢˜æ‰«æ...")
        print("=" * 60)
        
        # Get all markdown files (excluding backups)
        md_files = [f for f in self.docs_dir.glob("*.md") 
                   if not 'backup' in f.name]
        self.stats['total_files'] = len(md_files)
        
        for md_file in md_files:
            self.stats['files_scanned'] += 1
            print(f"æ‰«æ: {md_file.name}")
            
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Run all checks
            self.check_broken_images(md_file, content)
            self.check_untranslated_content(md_file, content)
            self.check_code_blocks(md_file, content)
            self.check_malformed_markdown(md_file, content)
            self.check_frontmatter(md_file, content)
            self.check_special_characters(md_file, content)
            self.check_links(md_file, content)
            self.check_translation_quality(md_file, content)
        
        self.check_duplicate_files()
        self.check_missing_images()
        
        return self.generate_report()
    
    def check_broken_images(self, file_path, content):
        """Check for broken image references"""
        # Find all image references
        img_patterns = [
            r'!\[([^\]]*)\]\(([^\)]+)\)',  # Markdown images
            r'<img[^>]+src=["\']([^"\']+)["\']',  # HTML images
        ]
        
        for pattern in img_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                img_path = match[-1] if isinstance(match, tuple) else match
                
                # Check if image file exists
                if img_path.startswith('/'):
                    full_path = self.docs_dir.parent / img_path[1:]
                else:
                    full_path = file_path.parent / img_path
                
                if not full_path.exists() and not img_path.startswith('http'):
                    self.issues['broken_images'].append({
                        'file': file_path.name,
                        'image': img_path,
                        'line': self._find_line_number(content, img_path)
                    })
    
    def check_untranslated_content(self, file_path, content):
        """Check for untranslated English content"""
        # Skip frontmatter
        if '---' in content:
            parts = content.split('---')
            if len(parts) >= 3:
                content = '---'.join(parts[2:])
        
        # Common English phrases that might be missed
        english_patterns = [
            r'\b(The|This|That|These|Those|What|Where|When|Why|How)\b',
            r'\b(is|are|was|were|been|being|have|has|had)\b',
            r'\b(will|would|could|should|shall|might|may)\b',
            r'\b(for|and|but|or|nor|yet|so)\b',
            r'\b(with|without|through|during|before|after)\b',
        ]
        
        # Check for significant English content (more than 20% English words)
        english_word_count = 0
        total_words = len(re.findall(r'\b\w+\b', content))
        
        for pattern in english_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            english_word_count += len(matches)
        
        if total_words > 0:
            english_ratio = english_word_count / total_words
            if english_ratio > 0.2:  # More than 20% English
                self.issues['untranslated_content'].append({
                    'file': file_path.name,
                    'english_ratio': f"{english_ratio:.1%}",
                    'sample': content[:200] + '...' if len(content) > 200 else content
                })
    
    def check_code_blocks(self, file_path, content):
        """Check for malformed code blocks"""
        # Check for unclosed code blocks
        code_fence_count = content.count('```')
        if code_fence_count % 2 != 0:
            self.issues['code_blocks'].append({
                'file': file_path.name,
                'issue': 'æœªé—­åˆçš„ä»£ç å—',
                'fence_count': code_fence_count
            })
        
        # Check for code blocks with broken line breaks
        code_blocks = re.findall(r'```[\s\S]*?```', content)
        for block in code_blocks:
            if '<br>' in block or '<br/>' in block:
                self.issues['code_blocks'].append({
                    'file': file_path.name,
                    'issue': 'ä»£ç å—ä¸­åŒ…å« HTML æ¢è¡Œæ ‡ç­¾',
                    'sample': block[:100] + '...' if len(block) > 100 else block
                })
    
    def check_malformed_markdown(self, file_path, content):
        """Check for malformed markdown syntax"""
        # Check for broken link syntax
        if re.search(r'\[\s*\n\s*##', content):
            self.issues['malformed_markdown'].append({
                'file': file_path.name,
                'issue': 'é“¾æ¥è¯­æ³•æ–­è¡Œ',
                'pattern': '[æ¢è¡Œ## æ ‡é¢˜]'
            })
        
        # Check for incomplete links
        incomplete_links = re.findall(r'\[([^\]]+)\]\s*$', content, re.MULTILINE)
        if incomplete_links:
            self.issues['malformed_markdown'].append({
                'file': file_path.name,
                'issue': 'ä¸å®Œæ•´çš„é“¾æ¥',
                'count': len(incomplete_links)
            })
        
        # Check for escaped characters that shouldn't be escaped
        over_escaped = re.findall(r'\\([#\*\+\-\.])', content)
        if len(over_escaped) > 10:  # Too many escaped characters
            self.issues['malformed_markdown'].append({
                'file': file_path.name,
                'issue': 'è¿‡åº¦è½¬ä¹‰çš„å­—ç¬¦',
                'count': len(over_escaped)
            })
    
    def check_frontmatter(self, file_path, content):
        """Check frontmatter validity"""
        if not content.startswith('---'):
            self.issues['frontmatter'].append({
                'file': file_path.name,
                'issue': 'ç¼ºå°‘ frontmatter'
            })
        else:
            # Extract frontmatter
            parts = content.split('---')
            if len(parts) >= 3:
                frontmatter = parts[1]
                
                # Check for required fields
                if 'title:' not in frontmatter:
                    self.issues['frontmatter'].append({
                        'file': file_path.name,
                        'issue': 'ç¼ºå°‘ title å­—æ®µ'
                    })
                
                # Check for untranslated title
                if re.search(r'title:\s*["\']?[A-Za-z\s]+["\']?', frontmatter):
                    if not any(chinese in frontmatter for chinese in ['ä¸­æ–‡', 'é…ç½®', 'å®‰è£…', 'æ•™ç¨‹']):
                        self.issues['frontmatter'].append({
                            'file': file_path.name,
                            'issue': 'Title å¯èƒ½æœªç¿»è¯‘'
                        })
    
    def check_special_characters(self, file_path, content):
        """Check for problematic special characters"""
        # Check for unescaped angle brackets that might break Vue
        vue_like_patterns = re.findall(r'<([a-z-]+)>', content)
        for pattern in vue_like_patterns:
            if pattern not in ['img', 'div', 'span', 'p', 'a', 'br', 'hr']:
                self.issues['special_characters'].append({
                    'file': file_path.name,
                    'issue': f'å¯èƒ½è¢«è¯¯è®¤ä¸º Vue ç»„ä»¶: <{pattern}>',
                    'pattern': f'<{pattern}>'
                })
        
        # Check for control characters
        control_chars = re.findall(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', content)
        if control_chars:
            self.issues['special_characters'].append({
                'file': file_path.name,
                'issue': 'åŒ…å«æ§åˆ¶å­—ç¬¦',
                'count': len(control_chars)
            })
    
    def check_links(self, file_path, content):
        """Check internal links"""
        # Find all internal links
        internal_links = re.findall(r'\]\((/[^\)]+)\)', content)
        
        for link in internal_links:
            # Check if link uses correct format
            if not link.endswith('.html') and link != '/' and not link.startswith('/img/'):
                if not link.startswith('http'):
                    self.issues['links'].append({
                        'file': file_path.name,
                        'link': link,
                        'issue': 'å†…éƒ¨é“¾æ¥åº”ä½¿ç”¨ .html æ‰©å±•å'
                    })
    
    def check_translation_quality(self, file_path, content):
        """Check translation quality issues"""
        # Check for machine translation artifacts
        machine_patterns = [
            r'Claude\s+Code',  # Should be translated or kept consistent
            r'npm\s+install',  # Commands should remain in English
            r'[A-Z]{2,}',  # All caps words (might be untranslated)
        ]
        
        # Check for inconsistent terminology
        terminology_issues = []
        
        # Check if mixing simplified and traditional Chinese
        simplified = re.findall(r'[ä¸ªè¿™é‚£æ²¡]', content)
        traditional = re.findall(r'[å€‹é€™é‚£æ²’]', content)
        
        if simplified and traditional:
            self.issues['translation_quality'].append({
                'file': file_path.name,
                'issue': 'æ··ç”¨ç®€ä½“å’Œç¹ä½“ä¸­æ–‡'
            })
    
    def check_duplicate_files(self):
        """Check for duplicate or backup files"""
        all_files = list(self.docs_dir.glob("*.md"))
        
        # Group files by base name
        file_groups = defaultdict(list)
        for f in all_files:
            base_name = re.sub(r'\.backup_\d+', '', f.stem)
            file_groups[base_name].append(f.name)
        
        for base_name, files in file_groups.items():
            if len(files) > 1:
                self.issues['duplicate_files'].append({
                    'base_name': base_name,
                    'files': files,
                    'count': len(files)
                })
    
    def check_missing_images(self):
        """Check for missing images in img directory"""
        img_dir = self.docs_dir.parent / 'img'
        if not img_dir.exists():
            self.issues['missing_images'].append({
                'issue': 'img ç›®å½•ä¸å­˜åœ¨'
            })
        else:
            # Check if common images exist
            expected_images = [
                'img/discovery',
                'img/supporters'
            ]
            
            for img_path in expected_images:
                full_path = self.docs_dir.parent / img_path
                if not full_path.exists():
                    self.issues['missing_images'].append({
                        'path': img_path,
                        'issue': 'é¢„æœŸçš„å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨'
                    })
    
    def _find_line_number(self, content, search_text):
        """Find line number of text in content"""
        lines = content.split('\n')
        for i, line in enumerate(lines, 1):
            if search_text in line:
                return i
        return 0
    
    def generate_report(self):
        """Generate comprehensive report"""
        self.stats['total_issues'] = sum(len(issues) for issues in self.issues.values())
        
        report = {
            'summary': self.stats,
            'issues': dict(self.issues),
            'severity_count': {
                'critical': 0,
                'warning': 0,
                'info': 0
            }
        }
        
        # Categorize by severity
        critical_types = ['broken_images', 'code_blocks', 'malformed_markdown', 'missing_images']
        warning_types = ['untranslated_content', 'frontmatter', 'special_characters', 'links']
        
        for issue_type, issues in self.issues.items():
            if issue_type in critical_types:
                report['severity_count']['critical'] += len(issues)
            elif issue_type in warning_types:
                report['severity_count']['warning'] += len(issues)
            else:
                report['severity_count']['info'] += len(issues)
        
        return report

def main():
    scanner = ComprehensiveIssueScanner()
    report = scanner.scan_all()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æ‰«ææŠ¥å‘Šæ€»ç»“")
    print("=" * 60)
    
    print(f"\nğŸ“ æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  - æ€»æ–‡ä»¶æ•°: {report['summary']['total_files']}")
    print(f"  - å·²æ‰«æ: {report['summary']['files_scanned']}")
    print(f"  - å‘ç°é—®é¢˜: {report['summary']['total_issues']}")
    
    print(f"\nâš ï¸ é—®é¢˜ä¸¥é‡æ€§:")
    print(f"  - ğŸ”´ ä¸¥é‡: {report['severity_count']['critical']}")
    print(f"  - ğŸŸ¡ è­¦å‘Š: {report['severity_count']['warning']}")
    print(f"  - ğŸ”µ ä¿¡æ¯: {report['severity_count']['info']}")
    
    if report['issues']:
        print("\nğŸ“‹ é—®é¢˜è¯¦æƒ…:")
        
        for issue_type, issues in report['issues'].items():
            if issues:
                print(f"\n### {issue_type.replace('_', ' ').title()} ({len(issues)} ä¸ª)")
                
                # Show first 3 issues as examples
                for issue in issues[:3]:
                    print(f"  - {json.dumps(issue, ensure_ascii=False, indent=4)}")
                
                if len(issues) > 3:
                    print(f"  ... è¿˜æœ‰ {len(issues) - 3} ä¸ªé—®é¢˜")
    
    # Save full report
    with open('comprehensive_issue_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: comprehensive_issue_report.json")
    
    # Generate actionable summary
    print("\n" + "=" * 60)
    print("ğŸ¯ å»ºè®®çš„ä¿®å¤ä¼˜å…ˆçº§:")
    print("=" * 60)
    
    if report['severity_count']['critical'] > 0:
        print("\n1. ğŸ”´ ç«‹å³ä¿®å¤ (å½±å“åŠŸèƒ½):")
        if 'broken_images' in report['issues'] and report['issues']['broken_images']:
            print(f"   - ä¿®å¤ {len(report['issues']['broken_images'])} ä¸ªæŸåçš„å›¾ç‰‡å¼•ç”¨")
        if 'code_blocks' in report['issues'] and report['issues']['code_blocks']:
            print(f"   - ä¿®å¤ {len(report['issues']['code_blocks'])} ä¸ªä»£ç å—é—®é¢˜")
        if 'malformed_markdown' in report['issues'] and report['issues']['malformed_markdown']:
            print(f"   - ä¿®å¤ {len(report['issues']['malformed_markdown'])} ä¸ª Markdown è¯­æ³•é—®é¢˜")
    
    if report['severity_count']['warning'] > 0:
        print("\n2. ğŸŸ¡ å»ºè®®ä¿®å¤ (å½±å“è´¨é‡):")
        if 'untranslated_content' in report['issues'] and report['issues']['untranslated_content']:
            print(f"   - ç¿»è¯‘ {len(report['issues']['untranslated_content'])} ä¸ªé¡µé¢çš„å‰©ä½™è‹±æ–‡å†…å®¹")
        if 'links' in report['issues'] and report['issues']['links']:
            print(f"   - ä¿®æ­£ {len(report['issues']['links'])} ä¸ªé“¾æ¥æ ¼å¼")
    
    print("\nâœ… æ‰«æå®Œæˆ!")

if __name__ == "__main__":
    main()